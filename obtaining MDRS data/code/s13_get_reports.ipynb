{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all season 13reports. landing page https://sites.google.com/a/marssociety.org/mdrs2013/crew-reports\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to individual reports from the landing page.\n",
    "url = urllib.request.urlopen('https://sites.google.com/a/marssociety.org/mdrs2013/previous-field-seasons/2013-field-season/crew-reports').read()\n",
    "soup = bs(url, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [] #there are links to same reports; will have to remove duplicates from final dateframe \n",
    "\n",
    "for x in soup.find_all('tbody'):\n",
    "    for y in x.find_all('a'):\n",
    "        if 'crew-' in str(y['href']) in str(y['href']):              \n",
    "            links.append(y['href'])    \n",
    "            \n",
    "links = list(set(links)) #remove duplicates   \n",
    "#print(links)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_link = 'http://mdrs.marssociety.org/home/crew-140/422-commanderreport'\n",
    "\n",
    "#links that do not have sites.google.com/a/ do not work. Need to add that part to links\n",
    "#http://mdrs.marssociety.org/home/crew-140/422-commanderreport\n",
    "#https://sites.google.com/a/marssociety.org/mdrs2013/home/crew-133/112-greenhabreport\n",
    "#https://sites.google.com/a/mdrs.marssociety.org/mdrs2013/home/crew-140/422-commanderreport\n",
    "#https://sites.google.com/a/mdrs.marssociety.org/home/crew-140/422-commanderreport\n",
    "\n",
    "#'https://sites.google.com/a/'+ broken_link.split('//')[1]\n",
    "\n",
    "\n",
    "#'mdrs.marssociety.org/home/crew-140/422-commanderreport'\n",
    "\n",
    "\n",
    "#broken_link.rsplit('/',2)[1] + '/' + broken_link.rsplit('/', 2)[2]\n",
    "#broken_link.split('//')[1].split('.',1)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process single link\n",
    "#link = 'https://sites.google.com/a/marssociety.org/mdrs2013/home/crew-139/411-commandercheckinreport'\n",
    "\n",
    "#url1 = urllib.request.urlopen(link).read()\n",
    "#link_soup = bs(url1, 'lxml')\n",
    "\n",
    "\n",
    "#check for good links - when bad link, put text as None \n",
    "# to fix broken links\n",
    "#'https://sites.google.com/a/' + broken_link.split('//')[1].split('.',1)[1].split('/',3)[0] + '/mdrs2013/home/' + broken_link.rsplit('/',2)[1] + '/' + broken_link.rsplit('/', 2)[2] #'mdrs.marssociety.org/mdrs2013/home/'\n",
    "\n",
    "fixed_links = []\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        url1 = urllib.request.urlopen(link).read()\n",
    "        fixed_links.append(link)\n",
    "    except urllib.error.HTTPError as exception:\n",
    "        link1 = 'https://sites.google.com/a/' + link.split('//')[1].split('.',1)[1].split('/',3)[0] + '/mdrs2013/home/' + link.rsplit('/',2)[1] + '/' + link.rsplit('/', 2)[2] \n",
    "        try:\n",
    "            url2 = urllib.request.urlopen(link1).read()\n",
    "            fixed_links.append(link1)\n",
    "        except urllib.error.HTTPError as exception:\n",
    "            print (link)\n",
    "            print (link1)\n",
    "            print (exception)\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_soup.h3.get_text().lower() # title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link.rsplit('/',2)[-2] #crew\n",
    "#link.rsplit('/',1)[-1].split('-')[0] #date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link_soup.find('tbody') #html\n",
    "link_soup.find('tbody').get_text() #text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all ;links\n",
    "#to check whether report is a good catch-all for reports\n",
    "# missing the following reports:\n",
    "# https://sites.google.com/a/marssociety.org/mdrs2013/home/crew-136/218-commandercheckin\n",
    "#https://sites.google.com/a/marssociety.org/mdrs2013/home/crew-136/217-commandercheckin\n",
    "crew = []\n",
    "date = []\n",
    "title =[]\n",
    "text = []\n",
    "html = [] \n",
    "url_links = []\n",
    "\n",
    "\n",
    "\n",
    "for l in fixed_links:\n",
    "    url1 = urllib.request.urlopen(l).read()\n",
    "    link_soup = bs(url1, 'lxml')\n",
    "    if 'report' in link_soup.h3.get_text().lower():\n",
    "        print(link_soup.h3.get_text().lower())\n",
    "        url_links.append(l) #link\n",
    "        title.append(link_soup.h3.get_text().lower()) #title\n",
    "        crew.append(l.rsplit('/',2)[-2]) # crew number \n",
    "        date.append(l.rsplit('/',1)[-1].split('-')[0]) #date\n",
    "        html.append(link_soup.tbody) #html\n",
    "        text.append(link_soup.tbody.get_text()) # text\n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.DataFrame({'crew': crew, 'date': date, 'header': title, 'body':text, 'html': html, 'link': url_links})\n",
    "\n",
    "\n",
    "#fix crew-xx into xx\n",
    "for i in range(len(reports)):\n",
    "    reports['crew'].iloc[i] = reports['crew'].iloc[i].split(\"crew-\")[1]\n",
    "   # print(i, reports['crew'].iloc[i])\n",
    "\n",
    "reports.to_csv('s13_reports.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}