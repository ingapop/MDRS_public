{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script gets person name and biography from mdrs crews 182-223 \n",
    "#Missing a lot of crews; entered the rest of data manually. \n",
    "#Output: 'bios_182-223.csv' in the same folder as the code. \n",
    "#uses function from fun_person_bio.ipyb (keep these 2 files in one folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nbimporter\n",
    "import requests\n",
    "import urllib.request\n",
    "import csv\n",
    "import urllib.request\n",
    "import importlib\n",
    "from fun_person_bio import get_person_bio\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of urls for crews 182-223\n",
    "all_links=[]\n",
    "\n",
    "for i in range(182,224):\n",
    "    all_links.append(\"http://mdrs.marssociety.org/crew-\" + str(i))\n",
    "#print(all_links)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop thru url list; check for broken links. \n",
    "\n",
    "working_links = []\n",
    "\n",
    "for link in all_links:\n",
    "    try:\n",
    "        url1 = urllib.request.urlopen(link).read()\n",
    "        working_links.append(link)\n",
    "    except urllib.error.HTTPError as exception:\n",
    "        print (link)\n",
    "        print (exception)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(working_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop thru all crews and see if it works.Checking for links that need to be processed differently.  \n",
    "\n",
    "for link in working_links:\n",
    "    x,y = get_person_bio(link)\n",
    "    if len(x)<1:\n",
    "        print(\"empty\", link)\n",
    "\n",
    "#crews 189 190 194 201 204 207 210 212 213 217 have different page structure and this code does not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to get crew number, person and bio. Apparently, there are 3 empty bios.  \n",
    "\n",
    "\n",
    "crews = []\n",
    "people = []\n",
    "bios = []\n",
    "\n",
    "for i in range(len(working_links)):\n",
    "    #need to keep data only from those links that can be scraped using this code (e.g. those that return not empty cells)\n",
    "    #will process other links separately.\n",
    "    c,x,y = get_person_bio(working_links[i])\n",
    "    if len(x)>1:\n",
    "        crews.append(c)\n",
    "        people.append(x)\n",
    "        bios.append(y)\n",
    "    print(working_links[i],len(c), len(x), len(y) ) #checking if all the same length. \n",
    "        \n",
    "        \n",
    "        \n",
    "#Problem crews: (link, len crew#, len people # len bio #)\n",
    "#http://mdrs.marssociety.org/crew-198 10 10 9  \n",
    "#http://mdrs.marssociety.org/crew-189 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-190 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-191 2 2 2\n",
    "#http://mdrs.marssociety.org/crew-192 2 2 0    \n",
    "#http://mdrs.marssociety.org/crew-194 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-198 10 10 9\n",
    "#http://mdrs.marssociety.org/crew-201 0 0 0 \n",
    "#http://mdrs.marssociety.org/crew-204 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-207 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-210 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-212 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-213 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-217 0 0 0\n",
    "#http://mdrs.marssociety.org/crew-214 3 3 3 #should be 4, will still include but add missing manually. \n",
    "#remove these from the link list; do them manually. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crews = []\n",
    "people =[]\n",
    "bios = []\n",
    "links =[]\n",
    "\n",
    "for i in range(len(working_links)):\n",
    "    #need to keep data only from those links that can be scraped using this code (e.g. those that return not empty cells)\n",
    "    #will process other links separately.\n",
    "    c,x,y,l = get_person_bio(working_links[i])\n",
    "    if len(x)>1:\n",
    "        if len(x)==len(y): #if getting the same # of people and bios from the page. \n",
    "            crews.append(c)\n",
    "            people.append(x)\n",
    "            bios.append(y)\n",
    "            links.append(l)\n",
    "            print(working_links[i],len(c), len(x), len(y), len(l) )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(crews)):\n",
    "    print(len(crews[i]), len(people[i]), len(bios[i]), len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten lists of lists\n",
    "\n",
    "crew_flat = [val for sublist in crews for val in sublist]\n",
    "people_flat = [val for sublist in people for val in sublist]\n",
    "bios_flat = [val for sublist in bios for val in sublist]\n",
    "links_flat = [val for sublist in links for val in sublist]\n",
    "\n",
    "print (len(crew_flat), len(people_flat), len(bios_flat), len(links_flat))\n",
    "\n",
    "print(len(crews), len(people), len(bios), len (links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output panda frame of crews that worked. The rest will fill manually :(\n",
    "\n",
    "data = pd.DataFrame({'crew': crew_flat,  'person': people_flat, 'bio': bios_flat, 'link': links_flat})\n",
    "data.to_csv(r'bios_182-223.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}